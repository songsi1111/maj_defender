{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 11:16:32.988880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 11:16:33.000599: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 11:16:33.004127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 11:16:33.013467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 11:16:33.653520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727838995.893914    4509 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-02 11:16:35.923243: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "{'1m': 0, '2m': 1, '3m': 2, '4m': 3, '5m': 4, '6m': 5, '7m': 6, '8m': 7, '9m': 8, '1s': 9, '2s': 10, '3s': 11, '4s': 12, '5s': 13, '6s': 14, '7s': 15, '8s': 16, '9s': 17, '1p': 18, '2p': 19, '3p': 20, '4p': 21, '5p': 22, '6p': 23, '7p': 24, '8p': 25, '9p': 26, '1z': 27, '2z': 28, '3z': 29, '4z': 30, '5z': 31, '6z': 32, '7z': 33}\n",
      "开始读取JSON数据\n",
      "开始预处理数据\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, concatenate,Layer, Conv1D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.config.optimizer.set_jit(False)\n",
    "tf.keras.backend.clear_session()\n",
    "# 混合精度\n",
    "set_global_policy('mixed_float16')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# 定义牌的类型和范围\n",
    "type_encoding = {'?':0, 'moqie':1, 'chipenggang':2}\n",
    "suits = [\n",
    "    '1m','2m','3m','4m','5m','6m','7m','8m','9m',\n",
    "    '1s','2s','3s','4s','5s','6s','7s','8s','9s',\n",
    "    '1p','2p','3p','4p','5p','6p','7p','8p','9p',\n",
    "    '1z','2z','3z','4z','5z','6z','7z'\n",
    "]\n",
    "# 初始化编码字典\n",
    "tile_encoding = {}\n",
    "index = 0\n",
    "# 生成摸入-切出组合\n",
    "for suit in suits:\n",
    "    action = f\"{suit}\"  # 组合形式，例如 '1m_1m'\n",
    "    tile_encoding[action] = index\n",
    "    index += 1\n",
    "print(tile_encoding)\n",
    "\n",
    "def encode_to_onehot(tile_in,tile_out,max_len=18):\n",
    "    tile_in = ['5' + tile[1:] if tile in ['0m', '0s', '0p'] else tile for tile in tile_in]\n",
    "    tile_out = ['5' + tile[1:] if tile in ['0m', '0s', '0p'] else tile for tile in tile_out]\n",
    "\n",
    "    types =  [type_encoding[f'{in_tile}'] for in_tile in tile_in]\n",
    "    tiles =  [tile_encoding[f'{out_tile}'] for out_tile in tile_out]\n",
    "    onehot1 = np.zeros((max_len, len(type_encoding)))  # 序列长度为 max_len\n",
    "    for i, idx in enumerate(types):\n",
    "        if i >= max_len:\n",
    "            break\n",
    "        onehot1[i, idx] = 1\n",
    "    onehot2 = np.zeros((max_len, len(tile_encoding)))  # 序列长度为 max_len\n",
    "    for i, idx in enumerate(tiles):\n",
    "        if i >= max_len:\n",
    "            break\n",
    "        onehot2[i, idx] = 1\n",
    "    return onehot1, onehot2\n",
    "def preprocess_data(data):\n",
    "    X_out=[]\n",
    "    X_in=[]\n",
    "    y=[]\n",
    "    for entry in data[\"results\"]:\n",
    "        onehot1, onehot2=encode_to_onehot(entry['tile_in'], entry['tile_out'])\n",
    "        X_in.append(onehot1)\n",
    "        X_out.append(onehot2)\n",
    "        y.append(1 if entry['tingpai'] else 0)\n",
    "    X_out = np.array(X_out)\n",
    "    X_in = np.array(X_in)\n",
    "    y = np.array(y)\n",
    "    return X_out,X_in,y\n",
    "\n",
    "print(\"开始读取JSON数据\")\n",
    "with open('output', 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(\"开始预处理数据\")\n",
    "X_out,X_in,y=preprocess_data(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型\n",
      "Epoch 1/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 10ms/step - accuracy: 0.8707 - loss: 0.3113 - val_accuracy: 0.8820 - val_loss: 0.2811 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.8820 - loss: 0.2786 - val_accuracy: 0.8895 - val_loss: 0.2713 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.8842 - loss: 0.2755 - val_accuracy: 0.8913 - val_loss: 0.2633 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.2558 - val_accuracy: 0.9012 - val_loss: 0.2507 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9023 - loss: 0.2425 - val_accuracy: 0.9082 - val_loss: 0.2366 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.9121 - loss: 0.2203 - val_accuracy: 0.9133 - val_loss: 0.2303 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9205 - loss: 0.2008 - val_accuracy: 0.9215 - val_loss: 0.2035 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - accuracy: 0.9318 - loss: 0.1769 - val_accuracy: 0.9230 - val_loss: 0.1982 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9369 - loss: 0.1643 - val_accuracy: 0.9348 - val_loss: 0.1759 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 10ms/step - accuracy: 0.9470 - loss: 0.1455 - val_accuracy: 0.9379 - val_loss: 0.1687 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9514 - loss: 0.1315 - val_accuracy: 0.9487 - val_loss: 0.1537 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9556 - loss: 0.1192 - val_accuracy: 0.9486 - val_loss: 0.1507 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.1116 - val_accuracy: 0.9459 - val_loss: 0.1527 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9653 - loss: 0.0953 - val_accuracy: 0.9503 - val_loss: 0.1370 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9663 - loss: 0.0928 - val_accuracy: 0.9546 - val_loss: 0.1366 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - accuracy: 0.9694 - loss: 0.0848 - val_accuracy: 0.9548 - val_loss: 0.1318 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0776 - val_accuracy: 0.9620 - val_loss: 0.1153 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.0694 - val_accuracy: 0.9624 - val_loss: 0.1216 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0651 - val_accuracy: 0.9632 - val_loss: 0.1161 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0492 - val_accuracy: 0.9666 - val_loss: 0.1129 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0399 - val_accuracy: 0.9697 - val_loss: 0.1112 - learning_rate: 5.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0344 - val_accuracy: 0.9712 - val_loss: 0.1132 - learning_rate: 5.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0327 - val_accuracy: 0.9710 - val_loss: 0.1175 - learning_rate: 5.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0244 - val_accuracy: 0.9740 - val_loss: 0.1179 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0194 - val_accuracy: 0.9758 - val_loss: 0.1154 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0162 - val_accuracy: 0.9765 - val_loss: 0.1220 - learning_rate: 1.2500e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0128 - val_accuracy: 0.9763 - val_loss: 0.1278 - learning_rate: 1.2500e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0127 - val_accuracy: 0.9763 - val_loss: 0.1301 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0098 - val_accuracy: 0.9764 - val_loss: 0.1312 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m4527/4527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0089 - val_accuracy: 0.9764 - val_loss: 0.1335 - learning_rate: 3.1250e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77f8b139b2c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个简单的注意力机制层\n",
    "class Attention(Layer):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # 输入: (batch_size, timesteps, units)\n",
    "        score = tf.matmul(inputs, inputs, transpose_b=True)  # 计算相似性分数\n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)  # 计算权重\n",
    "        context_vector = tf.matmul(attention_weights, inputs)  # 根据权重计算上下文向量\n",
    "        return context_vector\n",
    "# 构建LSTM模型\n",
    "def build_model(input_shape,input_shape2):\n",
    "    input1 = Input(shape=input_shape)\n",
    "    input2 = Input(shape=input_shape2)\n",
    "    x1 = LSTM(64, return_sequences=True)(input1)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x1 = LSTM(32)(x1)\n",
    "\n",
    "    x2 = LSTM(64, return_sequences=True)(input2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    x2 = LSTM(32)(x2)\n",
    "\n",
    "    merged = concatenate([x1, x2])\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(inputs=[input1, input2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train_in, X_test_in, X_train_out, X_test_out, y_train, y_test  = train_test_split(X_in,X_out, y, test_size=0.1, random_state=42)\n",
    "\n",
    "input_shape_in = (X_in.shape[1], X_in.shape[2])\n",
    "input_shape_out = (X_out.shape[1], X_out.shape[2])\n",
    "model = build_model(input_shape_in, input_shape_out)\n",
    "\n",
    "print(\"开始训练模型\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "model.fit([X_train_in, X_train_out], y_train, epochs=30, batch_size=16, validation_data=([X_test_in, X_test_out], y_test), callbacks=[reduce_lr])\n",
    "# model.fit([X_train_in, X_train_out], y_train, epochs=30, batch_size=16, validation_data=([X_test_in, X_test_out], y_test))\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "# model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832ms/step - accuracy: 0.2500 - loss: 3.4676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]] [0 0 0 0]\n",
      "Test Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "# 正式读入测试数据\n",
    "with open('pa.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "X_test_out,X_test_in,y_test=preprocess_data(data)\n",
    "print(y)\n",
    "test_loss, test_acc = model.evaluate([X_test_in, X_test_out], y_test)\n",
    "y_pred = model.predict([X_test_in, X_test_out])\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "print(y_pred_classes,y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Probility: [[9.990e-01]\n",
      " [3.397e-05]\n",
      " [9.907e-01]\n",
      " [8.955e-01]]\n",
      "Predicted classes: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model.keras')\n",
    "\n",
    "# 正式读入测试数据\n",
    "with open('pa.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "X_test_out,X_test_in,y_test=preprocess_data(data)\n",
    "y_pred = model.predict([X_test_in, X_test_out])\n",
    "y_pred = model.predict([X_test_in, X_test_out])\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "print(\"Probility:\", y_pred)\n",
    "print(\"Predicted classes:\", y_pred_classes)\n",
    "# print(\"Actual y_test:\", y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
